# svr_rbf_pipeline.py
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV, RepeatedKFold, cross_val_score
from sklearn.metrics import make_scorer, mean_squared_error
from joblib import dump

# ---------------- config ----------------
DATA_PATH = "data.csv"  # <-- put your file here
ID_COL = "psuid"
TARGET = "actual_capped_cagr"
# columns you have (adjust if needed)
num_cols = ["v1","v2","v3","v4","v5","v6","v7","v8","gp_0_count","prp_diabetic"]
cat_cols = ["naics_category"]  # looks binary, but we'll one-hot it safely

# ---------------- load ----------------
df = pd.read_csv(DATA_PATH)
df = df.dropna(subset=[TARGET])  # keep rows with target
X = df.drop(columns=[TARGET, ID_COL], errors="ignore")
y = df[TARGET].astype(float)

# ---------------- feature engineering ----------------
# (a) log1p for skewed count
log1p = FunctionTransformer(lambda x: np.log1p(x), feature_names_out="one-to-one")

# (b) numeric branch: log1p on gp_0_count, then poly degree=2, then scale
num_poly = Pipeline(steps=[
    ("split_cols", ColumnTransformer([
        ("log_count", Pipeline([("log", log1p)]), ["gp_0_count"]),
        ("pass_rest", "passthrough", [c for c in num_cols if c != "gp_0_count"])
    ], remainder="drop")),
    ("poly", PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)),
    ("scale", StandardScaler())
])

# (c) categorical branch (binary-safe one-hot)
cat_pipe = Pipeline(steps=[
    ("onehot", OneHotEncoder(drop="if_binary", handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num_poly_scaled", num_poly, num_cols),
    ("cat", cat_pipe, cat_cols)
], remainder="drop")

# ---------------- model ----------------
svr = SVR(kernel="rbf")

pipe = Pipeline(steps=[
    ("prep", preprocessor),
    ("svr", svr)
])

# ---------------- tuning ----------------
param_grid = {
    "svr__C": [1, 3, 10, 30, 100],
    "svr__gamma": ["scale", 0.3, 0.1, 0.03, 0.01],
    "svr__epsilon": [0.001, 0.005, 0.01, 0.03]
}

cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)
rmse_scorer = make_scorer(lambda yt, yp: mean_squared_error(yt, yp, squared=False), greater_is_better=False)

grid = GridSearchCV(
    pipe,
    param_grid=param_grid,
    cv=cv,
    scoring=rmse_scorer,
    n_jobs=-1,
    verbose=1
)
grid.fit(X, y)

# ---------------- evaluation ----------------
best_pipe = grid.best_estimator_
cv_scores = cross_val_score(best_pipe, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)
print(f"[SVR RBF] Best params: {grid.best_params_}")
print(f"[SVR RBF] CV RMSE: {abs(cv_scores.mean()):.5f} Â± {cv_scores.std():.5f}")

# ---------------- save ----------------